{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cff9939-7af6-4f28-ba45-ce618cbb1c5e",
   "metadata": {},
   "source": [
    "# **Huggingface ü§ó** \n",
    "\n",
    "## **What's Covered?**\n",
    "1. Introduction to HuggingFace\n",
    "2. ü§ó Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329fbb8-6182-44ab-888c-8f8341d28a58",
   "metadata": {},
   "source": [
    "## **Introduction to HuggingFace**\n",
    "\n",
    "### **What is HuggingFace?**\n",
    "\n",
    "Hugging Face is a company and a community of opensource ML projects, most famous for NLP.  \n",
    "\n",
    "Hugging Face makes advanced AI, especially with large language models, accessible and practical for everyone. It provides the building blocks (pre-trained models, datasets) and the tools (libraries, platform) to quickly build, experiment with, and deploy AI applications without reinventing the wheel.\n",
    "\n",
    "### **HuggingFace Hub**\n",
    "**HuggingFace Hub** is a web-based platform which hosts the following:\n",
    "1. **Models Hub:** Thousands of pre-trained models (BERT, GPT, T5, etc.) for tasks like sentiment analysis, translation, summarization, and more. Go to: [https://huggingface.co/models](https://huggingface.co/models) and click on any model. Pick a task you're interested in (like \"text-generation\"), find a popular model, and read its model card.  When you click on the model name, you'll find:\n",
    "    - Model card (what a model does)\n",
    "    - Usage code\n",
    "    - License\n",
    "    - Downloads\n",
    "    - Metrics\n",
    "    - Files (like pytorch_model.bin, config.json, tokenizer.json)\n",
    "2. **Datasets Hub:** Access and share a vast collection of datasets. High-quality data is the fuel for AI models, and Hugging Face offers a convenient way to find and utilize ready-to-use datasets for various tasks.\n",
    "3. **Spaces:** Create and host interactive demos of your machine learning models or applications directly in your browser. This allows for easy sharing and showcasing of your work.\n",
    "4. **Other Tools:** It also provides various other tools and services for things like automatic model training (AutoTrain) and **Inference APIs** for easy deployment.\n",
    "5. **Hub for Vision, Audio, and Multimodal Models:** Not limited to text anymore.\n",
    "\n",
    "\n",
    "### **Key libraries**\n",
    "1. `ü§ó Transformers:` This is the flagship library. It provides a unified API for working with state-of-the-art \"Transformer\" models (the \"T\" in GPT, BERT, etc.). These models are incredibly powerful for understanding and generating human language. With `transformers`, you can load, use, and fine-tune these models with just a few lines of code, regardless of whether you're using PyTorch or TensorFlow.\n",
    "2. `ü§ó Datasets:` This library simplifies the process of loading, processing, and sharing datasets for machine learning. It's highly efficient for handling large datasets.\n",
    "3. `ü§ó Evaluate:`\n",
    "4. `ü§ó Tokenizers:` Before a language model can understand text, it needs to break it down into smaller pieces called \"tokens.\" The tokenizers library provides highly optimized tokenizers for various models, ensuring your data is in the right format for the models to consume.\n",
    "5. `ü§ó Accelerate:` A library that helps you train your models on different hardware setups (e.g., multiple GPUs, distributed training) with minimal code changes.\n",
    "\n",
    "### **Open Source and Framework Agnostic**\n",
    "- By providing pre-trained models and easy-to-use APIs, it dramatically speeds up the development cycle.\n",
    "- The open-source nature fosters a collaborative environment, leading to faster advancements and more robust solutions.\n",
    "- It supports popular deep learning frameworks like PyTorch and TensorFlow, giving developers flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fc587-d930-4356-84cf-49adb25f1eee",
   "metadata": {},
   "source": [
    "## **ü§ó Transformers**\n",
    "\n",
    "### **What is ü§ó Transformers?**\n",
    "ü§ó Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as:\n",
    "\n",
    "**üìù Natural Language Processing:** text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.  \n",
    "**üñºÔ∏è Computer Vision:** image classification, object detection, and segmentation.  \n",
    "**üó£Ô∏è Audio:** automatic speech recognition and audio classification.  \n",
    "**üêô Multimodal:** table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.  \n",
    "\n",
    "ü§ó Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a model‚Äôs life; train a model in three lines of code in one framework, and load it for inference in another. Models can also be exported to a format like ONNX and TorchScript for deployment in production environments.\n",
    "\n",
    "### **Installation**\n",
    "1. `transformers` can run on top of either PyTorch or TensorFlow. You need at least one of them installed.\n",
    "2. For PyTorch\n",
    "```\n",
    "! pip install torch\n",
    "```\n",
    "3. For TensorFlow\n",
    "```\n",
    "! pip install tensorflow\n",
    "! pip install tf-keras\n",
    "```\n",
    "4. Installing transformers\n",
    "```\n",
    "! pip install transformers\n",
    "```\n",
    "5. Installing tokenizers for fast tokenization\n",
    "```\n",
    "! pip install tokenizers\n",
    "```\n",
    "6. Installing datasets for efficient data loading and processing\n",
    "```\n",
    "! pip install datasets\n",
    "```\n",
    "7. Installing accelerate for easy distributed training\n",
    "```\n",
    "! pip install accelerate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c91cc-565b-4081-bf88-dd359066da03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b496c3-9374-45ff-9d81-122727458509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e97ce3-2446-49cc-bd50-34a5fd81c171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93281c0-832c-481b-817e-8d65a3b67fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bb890-9fe8-43aa-8961-6a9484b1e2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6be030-6394-40ea-819d-992c3745dbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c12ce9-9e7d-4a4f-a948-256a6bcc921f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f7287-9a7c-4fb5-9446-29ac39596248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9b67d-35a1-42b3-93ca-24dba126a786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d742f7f-68a5-48fb-90c2-f9d6c4e58388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf12e84-b5a6-4c52-a2b5-fea97daa0a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972aec54-d7a1-41bc-b64b-b82b4511cd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a14b5-e1e0-4d8d-9093-05a0fe8bad2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
